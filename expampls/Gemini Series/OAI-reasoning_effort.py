from openai import OpenAI

client = OpenAI(
    api_key="sk-***", # ðŸ”‘ æ¢æˆä½ åœ¨ AiHubMix ç”Ÿæˆçš„å¯†é’¥
    base_url="https://aihubmix.com/v1",
)

completion = client.chat.completions.create(
    model="gemini-2.5-flash-preview-04-17",
    reasoning_effort="low", #"low", "medium", and "high", which behind the scenes we map to 1K, 8K, and 24K thinking token budgets. If you want to disable thinking, you can set the reasoning effort to "none".
    messages=[
        {
            "role": "user",
            "content": "é‡‘èžé¢†åŸŸçš„ã€Œ72 æ³•åˆ™ã€æ˜¯å¦‚ä½•æŽ¨å¯¼çš„ï¼Ÿ"
        }
    ],
    stream=True
)

#print(completion.choices[0].message.content)

for chunk in completion:
    # æ‰“å°å†…å®¹éƒ¨åˆ†
    print(chunk.choices[0].delta)
    # åªåœ¨æœ€åŽä¸€ä¸ª chunkï¼ˆåŒ…å«å®Œæ•´ usage æ•°æ®ï¼‰æ—¶æ‰“å° usage ä¿¡æ¯
    if chunk.usage and chunk.usage.completion_tokens > 0:
        print(f"è¾“å‡º tokens: {chunk.usage.completion_tokens}")
        print(f"è¾“å…¥ tokens: {chunk.usage.prompt_tokens}")
        print(f"æ€» tokens: {chunk.usage.total_tokens}")